# The name of the cluster where this will be installed. Metrics, Logs & Events will have a cluster label with this value.
# Traces will have a cluster attribute with this value
clusterLabelValue: "meta"

# The environment (dev, staging, prod, etc..) where this will be installed. Metrics, Logs & Events will have an environment label with this value.
# Traces will have an environment attribute with this value
# Included to assist with alert notification routing, when cluster label values might be ambiguous
environmentLabelValue: "prod"

#####################################################################################################
# Grafana Alloy Configurations
# This chart can install 4 different Grafana Alloy Deployments. Each can be enabled or disabled.
# 1. alloy-metrics installs alloy as a replicaset, and can be configured to discover and scrape
#    metrics from Mimir, Loki, Tempo, Grafana and other services/exporters important for
#    meta-monitoring your Grafana Observability Stack.
# 2. alloy-logs installs Grafana Alloy as a daemonset on each node and ingests pod logs for each pod
#    in the specified namespaces.
# 3. alloy-events installs Grafana Alloy as a replicaset and ingests kubernetes events for the 
#    specified namespaces.
# 4. alloy-traces install Grafana Alloy as a replicaset and collects traces sent from Grafana, 
#    Mimir, Loki and Tempo. Each must be configured to enable traces as well as the alloy-traces
#    endpoint to send their traces to.
########################################################################################################

########################################################################################################
# Grafana Alloy Metrics Configuration
# Enable the components you need. Disable the ones you don't.
########################################################################################################
alloy-metrics:
  # Set to false to not collect any metrics
  enabled: true
  # Enable to collect metrics from Grafana Mimir/Grafana Enterprise Metrics in the specified namespace
  mimir:
    enabled: true
    namespace: gem
    
  # Enable to collect metrics from Grafana Loki/Grafana Enterprise Logs in the specified namespace
  loki:
    enabled: true
    namespace: gel
    
  # Enable to collect metrics from Grafana Tempo/Grafana Enterprise Traces in the specified namespace
  tempo:
    enabled: true
    namespace: get
    
  # Enable to collect metrics from Grafana/Grafana Enterprise in the specified namespace
  grafana:
    enabled: true
    namespace: ge
    
  # Enable to collect metrics from other Grafana Alloy deployments in the specified namespace
  alloy:
    enabled: true
    namespace: alloy
    
  # Enable to collect metrics from Grafana Alloy deployments used in the meta-monitoring deployment in the specified namespace
  meta-monitoring:
    enabled: true

  # Enable to collect node_exporter metrics.
  # Node Exporter must be installed separately, or as a part of this chart. See https://github.com/prometheus-community/helm-charts/blob/main/charts/prometheus-node-exporter
  # Ensure your label selector(s) match
  node_exporter:
    enabled: true

    labelSelectors:
      - "app.kubernetes.io/name=node-exporter"
      - "app.kubernetes.io/purpose=meta-monitoring"

  # Enable to collect kube state metrics from the specified namespaces
  # Kube State Metrics must be installed separate. See https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-state-metrics
  kube_state_metrics:
    enabled: true

    labelSelectors:
      - "app.kubernetes.io/name=kube-state-metrics"
      - "app.kubernetes.io/purpose=meta-monitoring"

    # This should be the namespace kube-state-metrics is deployed to. If enabled via this chart, will be the release namespace
    namespacesToMonitor:
      - meta-monitoring

  # Enable to collect cadvisor metrics
  cadvisor:
    enabled: true
    # This should include the namespace of any enabled component namespaces
    namespacesToMonitor:
      - gem
      - gel
      - get
      - ge
      - alloy

  # Alloy Metrics deployment configuration
  nameOverride: alloy-metrics
  fullnameOverride: meta-monitoring-alloy-metrics

  crds:
    create: false

  alloy:
    clustering:
      enabled: true
      name: alloy-metrics
      portName: http
    configMap:
      create: false
      name: "alloy-metrics-config"
      key: 'config.alloy'
    resources:
      requests:
        cpu: '1000m'
        memory: '1Gi'
      limits:
        memory: '4Gi'
  controller:
    type: "statefulset"
    autoscaling:
      enabled: true
      minReplicas: 3
      maxReplicas: 30
      targetMemoryUtilizationPercentage: 90
      targetCPUUtilizationPercentage: 90


########################################################################################################
# Grafana Alloy Logs Configuration
# Specify the namespaces of your Grafana Observability Platform Deployments
########################################################################################################
alloy-logs:
  # Set to false to not collect logs
  enabled: true
  # Namespaces to collect pod logs from
  namespacesToMonitor:
    - gem
    - gel
    - get
    - ge
    - alloy

  # Alloy deployment configuration
  nameOverride: alloy-logs
  fullnameOverride: meta-monitoring-alloy-logs
  
  crds:
    create: false

  alloy:
    clustering:
      enabled: false
    configMap:
      create: false
      name: "alloy-logs-config"
      key: 'config.alloy'
    mounts:
      varlog: true
    resources:
      requests:
        cpu: '1000m'
        memory: '600Mi'
      limits:
        memory: '4Gi'
  controller:
    type: "daemonset"

########################################################################################################
# Grafana Alloy Traces Configuration
# Does not currently function.
########################################################################################################
alloy-traces:
  enabled: false

  nameOverride: alloy-traces
  fullnameOverride: meta-monitoring-alloy-traces
  crds:
    create: false
  alloy:
    clustering:
      enabled: false
    configMap:
      create: false
      name: "alloy-traces-config"
      key: 'config.alloy'
    resources:
      requests:
        cpu: '1000m'
        memory: '600Mi'
      limits:
        memory: '4Gi'
  controller:
    type: "statefulset"
    autoscaling:
      enabled: true
      minReplicas: 3
      maxReplicas: 10
      targetMemoryUtilizationPercentage: 90
      targetCPUUtilizationPercentage: 90

########################################################################################################
# Grafana Alloy Events Configuration
# Specify the namespaces of your Grafana Observability Platform Deployments
########################################################################################################
alloy-events:
  # Set to false to not collect logs
  enabled: true
  # Namespaces to collect pod logs from
  namespacesToMonitor:
    - gem
    - gel
    - get
    - ge
    - alloy

  # Alloy deployment configuration
  nameOverride: alloy-events
  fullnameOverride: meta-monitoring-alloy-events
  crds:
    create: false
  alloy:
    clustering:
      enabled: true
      name: alloy-events
    configMap:
      create: false
      name: "alloy-events-config"
      key: 'config.alloy'
    resources:
      requests:
        cpu: '1000m'
        memory: '600Mi'
      limits:
        memory: '4Gi'
  controller:
    type: "statefulset"
    autoscaling:
      enabled: true
      minReplicas: 1
      maxReplicas: 5
      targetMemoryUtilizationPercentage: 90
      targetCPUUtilizationPercentage: 90

#####################################################################################################
# Node Exporter
# Enable to deploy node-exporter as a daemonset to the cluster to collect node infrastructure metrics
# alloy_metrics.node_exporter.enabled must be set to true to scrape the metrics.
# Ensure that alloy_metrics.node_exporter.labelSelectors match the pod labels
#####################################################################################################
node-exporter:
  enabled: true

  service:
    annotations:
      metrics.agent.grafana.com/tenant: primary
      metrics.agent.grafana.com/scrape: "true"
  # Additional label created to provide a mechanism to prevent other telemetry collectors from scraping
  podLabels:
    app.kubernetes.io/purpose: meta-monitoring


#####################################################################################################
# Kube State Metrics
# Enable to deploy kube-state-metrics to the meta-monitoring namespace.
# alloy_metrics.kube_state_metrics.enabled must be set to true to scrape the metrics.
# Ensure that alloy_metrics.kube_state_metrics.labelSelectors match the pod labels
# Ensure that kube-state-metrics.namespaces list the namespaces of your observability stack
#####################################################################################################
kube-state-metrics:
  enabled: true

  service:
    annotations:
      metrics.agent.grafana.com/tenant: primary
      metrics.agent.grafana.com/scrape: "true"
  # Additional label created to provide a mechanism to prevent other telemetry collectors from scraping
  podLabels:
    app.kubernetes.io/purpose: meta-monitoring 

  # This should include the namespaces of any GE/GEM/GEL/GET/Alloy deployments
  namespaces:
    - gem
    - gel
    - get
    - ge
    - alloy
    - meta-monitoring

#####################################################################################################
# GRAFANA CLOUD
# Enable to send Metrics, Logs or Traces to a Grafana Cloud Instance (Recommended)
# A secret with the configured name must be deployed in the namespace you deploy meta-monitoring to.
# See Installation documentation for more info. 
#####################################################################################################
cloud:
  logs:
    enabled: true
    secret: "logs"
  metrics:
    enabled: true
    secret: "metrics"
  traces:
    enabled: true
    secret: "traces"

#####################################################################################################
# Local Deployment
# Enable to send Metrics, Logs or Traces to a local instance of Mimir, Loki or Tempo created by this
# helm chart. 
# Minio must be enabled if any of these are true. 
#####################################################################################################
local:
  grafana:
    enabled: false
  logs:
    enabled: false
  metrics:
    enabled: false
  traces:
    enabled: false
  minio:
    enabled: false 

grafana:
  version: 10.4.2
  # Gateway ingress configuration
  ingress:
    # -- Specifies whether an ingress for the gateway should be created
    enabled: true
    # -- Ingress Class Name. MAY be required for Kubernetes versions >= 1.18
    ingressClassName: ""
    # -- Annotations for the gateway ingress
    annotations: {}
    # -- Labels for the gateway ingress
    labels: {}
    # -- Hosts configuration for the gateway ingress, passed through the `tpl` function to allow templating
    hosts:
      - host: monitoring.example.com
        paths:
          - path: /
            # -- pathType (e.g. ImplementationSpecific, Prefix, .. etc.) might also be required by some Ingress Controllers
            pathType: Prefix
            # backend:
            #   service:
            #     name: TODO
            #     port:
            #       number: TODO
    # -- TLS configuration for the gateway ingress. Hosts passed through the `tpl` function to allow templating
    #tls:
    #  - secretName: grafana-tls
    #    hosts:
    #      - monitoring.example.com


# Set enabled = true to add the default logs dashboards to the local Grafana
dashboards:
  logs:
    enabled: true

loki:
  loki:
    auth_enabled: false
    schemaConfig:
      configs:
        - from: 2024-03-29
          store: tsdb
          object_store: s3
          schema: v13
          index:
            prefix: index_
            period: 24h
    storage:
      type: "s3"
      s3:
        insecure: true
        s3ForcePathStyle: true
      bucketNames:
        chunks: loki-chunks
        ruler: loki-ruler
    structuredConfig:
      common:
        storage:
          s3:
            access_key_id: "${rootUser}"
            endpoint: "{{ .Release.Name }}-minio.{{ .Release.Namespace }}.svc:9000"
            secret_access_key: "${rootPassword}"
      compactor:
        retention_enabled: true
        delete_request_store: s3
      limits_config:
        retention_period: 30d
  lokiCanary:
    enabled: false
  test:
    enabled: false
  monitoring:
    dashboards:
      enabled: false
    rules:
      enabled: false
    serviceMonitor:
      enabled: false
    selfMonitoring:
      enabled: false
      grafanaAgent:
        installOperator: false
    lokiCanary:
      enabled: false
  write:
    extraArgs:
    - "-config.expand-env=true"
    extraEnvFrom:
    - secretRef:
        name: "minio"
  read:
    extraArgs:
    - "-config.expand-env=true"
    extraEnvFrom:
    - secretRef:
        name: "minio"
  backend:
    extraArgs:
    - "-config.expand-env=true"
    extraEnvFrom:
    - secretRef:
        name: "minio"


mimir-distributed:
  minio:
    enabled: false
  global:
    extraEnvFrom:
    - secretRef:
        name: "minio"
  mimir:
    structuredConfig:
      alertmanager_storage:
        s3:
          bucket_name: mimir-ruler
      blocks_storage:
        backend: s3
        s3:
          bucket_name: mimir-tsdb
      ruler_storage:
        s3:
          bucket_name: mimir-ruler
      common:
        storage:
          backend: s3
          s3:
            bucket_name: mimir-ruler
            access_key_id: "${rootUser}"
            endpoint: "{{ .Release.Name }}-minio.{{ .Release.Namespace }}.svc:9000"
            secret_access_key: "${rootPassword}"
            insecure: true
      limits:
        compactor_blocks_retention_period: 30d


tempo-distributed:
  tempo:
    structuredConfig:
      storage:
        trace:
          backend: s3
          s3:
            bucket: tempo
            endpoint: "{{ .Release.Name }}-minio.{{ .Release.Namespace }}.svc:9000"
            access_key: "${rootUser}"
            secret_key: "${rootPassword}"
            insecure: true
  distributor:
    extraArgs:
    - "-config.expand-env=true"
    extraEnvFrom:
    - secretRef:
        name: "minio"
  ingester:
    extraArgs:
    - "-config.expand-env=true"
    extraEnvFrom:
    - secretRef:
        name: "minio"
  compactor:
    extraArgs:
    - "-config.expand-env=true"
    extraEnvFrom:
    - secretRef:
        name: "minio"
  querier:
    extraArgs:
    - "-config.expand-env=true"
    extraEnvFrom:
    - secretRef:
        name: "minio"
  queryFrontend:
    extraArgs:
    - "-config.expand-env=true"
    extraEnvFrom:
    - secretRef:
        name: "minio"
  traces:
    otlp:
      http:
        enabled: true
      grpc:
        enabled: true

minio:
  existingSecret: "minio"
  buckets:
    - name: loki-chunks
      policy: none
      purge: false
    - name: loki-ruler
      policy: none
      purge: false
    - name: tempo
      policy: none
      purge: false
    - name: mimir-ruler
      policy: none
      purge: false
    - name: mimir-tsdb
      policy: none
      purge: false
  mode: standalone
  persistence:
    size: 5Gi
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
  # Changed the mc config path to '/tmp' from '/etc' as '/etc' is only writable by root and OpenShift will not permit this.
  configPathmc: "/tmp/minio/mc/"
